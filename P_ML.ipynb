{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this ungraded lab, you can see how a linear regression model is defined in code, and you can see plots that show how well a \n",
    "model fits some data given choices of w and b.  You can also try different values of w and b to see if it improves the fit to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to implement the model  ùëìùë§,ùëè for linear regression with one variable \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('./deeplearning.mplstyle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Statement:\n",
    "\n",
    "As in the lecture, you will use the motivating example of housing price prediction.\n",
    "This lab will use a simple data set with only two data points - a house with 1000 square feet(sqft) sold for $300,000 and a house with 2000 square feet sold for $500,000. These two points will constitute our data or training set. In this lab, the units of size are 1000 sqft and the units of price are 1000s of dollars.\n",
    "\n",
    "Size (1000 sqft)\tPrice (1000s of dollars)\n",
    "1.0\t                       300\n",
    "2.0                        500\n",
    "\n",
    "You would like to fit a linear regression model (shown above as the blue straight line) through these two points, so you can then predict price for other houses - say, a house with 1200 sqft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train = [1. 2.]\n",
      "y_train = [300. 500.]\n"
     ]
    }
   ],
   "source": [
    "# x_train is the input variable (size in 1000 square feet)\n",
    "# y_train is the target (price in 1000s of dollars)\n",
    "x_train = np.array([1.0, 2.0])\n",
    "y_train = np.array([300.0, 500.0])\n",
    "print(f\"x_train = {x_train}\")\n",
    "print(f\"y_train = {y_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of training examples m\n",
    "You will use m to denote the number of training examples. Numpy arrays have a .shape parameter. x_train.shape returns a python tuple with an entry for each dimension. x_train.shape[0] is the length of the array and number of examples as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (2,)\n",
      "Number of training examples is: 2\n"
     ]
    }
   ],
   "source": [
    "# m is the number of training examples\n",
    "print(f\"x_train.shape: {x_train.shape}\")\n",
    "m = x_train.shape[0]\n",
    "print(f\"Number of training examples is: {m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples is: 2\n"
     ]
    }
   ],
   "source": [
    "# One can also use the Python len() function as shown below.\n",
    "\n",
    "# m is the number of training examples\n",
    "m = len(x_train)\n",
    "print(f\"Number of training examples is: {m}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training example x_i, y_i\n",
    "You will use ùë•^(ùëñ),ùë¶^(ùëñ) to denote the  ùëñùë°‚Ñé training example.Since Python is zero indexed,ùë•^(0),ùë¶^(0) is (1.0, 300.0) and ùë•^(1),ùë¶^(1) is (2.0, 500.0).\n",
    "To access a value in a Numpy array, one indexes the array with the desired offset. For example the syntax to access location zero of x_train is x_train[0]. Run the next code block below to get the  ùëñùë°‚Ñé training example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(x^(0), y^(0)) = (1.0, 300.0)\n"
     ]
    }
   ],
   "source": [
    "i = 0 # Change this to 1 to see (x^1, y^1)\n",
    "\n",
    "x_i = x_train[i]\n",
    "y_i = y_train[i]\n",
    "print(f\"(x^({i}), y^({i})) = ({x_i}, {y_i})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the data\n",
    "\n",
    "You can plot these two points using the scatter() function in the matplotlib library, as shown in the cell below.\n",
    "The function arguments marker and c show the points as red crosses (the default is blue dots).\n",
    "You can use other functions in the matplotlib library to set the title and labels to display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the data points\n",
    "plt.scatter(x_train, y_train, marker='x', c='r')\n",
    "# Set the title\n",
    "plt.title(\"Housing Prices\")\n",
    "# Set the y-axis label\n",
    "plt.ylabel('Price (in 1000s of dollars)')\n",
    "# Set the x-axis label\n",
    "plt.xlabel('Size (1000 sqft)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model function\n",
    "As described in lecture, the model function for linear regression (which is a function that maps from x to y) is represented as\n",
    "\n",
    "ùëìùë§,ùëè(ùë•^(ùëñ))=ùë§x^(ùëñ)+b\n",
    "\n",
    "The formula above is how you can represent straight lines - different values of  ùë§  and  ùëè  give you different straight lines on the plot. \n",
    "Let's try to get a better intuition for this through the code blocks below. Let's start with  ùë§=100 and  ùëè=100\n",
    "Note: You can come back to this cell to adjust the model's w and b parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: 100\n",
      "b: 100\n"
     ]
    }
   ],
   "source": [
    "w = 100\n",
    "b = 100\n",
    "print(f\"w: {w}\")\n",
    "print(f\"b: {b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compute the value of  ùëìùë§,ùëè(ùë•^(ùëñ)) for your two data points. You can explicitly write this out for each data point as -\n",
    "for  ùë•^(0), f_wb = w * x[0] + b\n",
    "for  ùë•^(1), f_wb = w * x[1] + b\n",
    "For a large number of data points, this can get unwieldy and repetitive. So instead, you can calculate the function output in a for loop as shown in the compute_model_output function below.\n",
    "\n",
    "Note: The argument description (ndarray (m,)) describes a Numpy n-dimensional array of shape (m,). (scalar) describes an argument without dimensions, just a magnitude.\n",
    "Note: np.zero(n) will return a one-dimensional numpy array with  ùëõ entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_model_output(x, w, b):\n",
    "    \"\"\"\n",
    "    Computes the prediction of a linear model\n",
    "    Args:\n",
    "      x (ndarray (m,)): Data, m examples \n",
    "      w,b (scalar)    : model parameters  \n",
    "    Returns\n",
    "      y (ndarray (m,)): target values\n",
    "    \"\"\"\n",
    "    m = x.shape[0]\n",
    "    f_wb = np.zeros(m)\n",
    "    for i in range(m):\n",
    "        f_wb[i] = w * x[i] + b\n",
    "        \n",
    "    return f_wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now let's call the compute_model_output function and plot the output..\n",
    "\n",
    "tmp_f_wb = compute_model_output(x_train, w, b,)\n",
    "\n",
    "# Plot our model prediction\n",
    "plt.plot(x_train, tmp_f_wb, c='b',label='Our Prediction')\n",
    "\n",
    "# Plot the data points\n",
    "plt.scatter(x_train, y_train, marker='x', c='r',label='Actual Values')\n",
    "\n",
    "# Set the title\n",
    "plt.title(\"Housing Prices\")\n",
    "# Set the y-axis label\n",
    "plt.ylabel('Price (in 1000s of dollars)')\n",
    "# Set the x-axis label\n",
    "plt.xlabel('Size (1000 sqft)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, setting  ùë§=100  and  ùëè=100  does not result in a line that fits our data.\n",
    "\n",
    "Challenge\n",
    "Try experimenting with different values of  ùë§  and  ùëè. What should the values be for a line that fits our data?\n",
    "\n",
    "Tip:\n",
    "You can use your mouse to click on the triangle to the left of the green \"Hints\" below to reveal some hints for choosing b and w.\n",
    "\n",
    "Prediction\n",
    "Now that we have a model, we can use it to make our original prediction. Let's predict the price of a house with 1200 sqft. Since the units of  ùë• are in 1000's of sqft,  ùë• is 1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$340 thousand dollars\n"
     ]
    }
   ],
   "source": [
    "w = 200                         \n",
    "b = 100    \n",
    "x_i = 1.2\n",
    "cost_1200sqft = w * x_i + b    \n",
    "\n",
    "print(f\"${cost_1200sqft:.0f} thousand dollars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goals\n",
    "In this lab you will:\n",
    "you will implement and explore the cost function for linear regression with one variable.\n",
    "\n",
    "Tools\n",
    "In this lab we will make use of:\n",
    "NumPy, a popular library for scientific computing\n",
    "Matplotlib, a popular library for plotting data\n",
    "local plotting routines in the lab_utils_uni.py file in the local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from lab_utils_uni import plt_intuition, plt_stationary, plt_update_onclick, soup_bowl\n",
    "plt.style.use('./deeplearning.mplstyle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Statement\n",
    "You would like a model which can predict housing prices given the size of the house.\n",
    "Let's use the same two data points as before the previous lab- a house with 1000 square feet sold for $300,000 and a house with 2000 square feet sold for $500,000.\n",
    "Size (1000 sqft)\tPrice (1000s of dollars)\n",
    "1\t                          300\n",
    "2\t                          500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([1.0, 2.0])           #(size in 1000 square feet)\n",
    "y_train = np.array([300.0, 500.0])           #(price in 1000s of dollars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below calculates cost by looping over each example. In each loop:\n",
    "f_wb, a prediction is calculated\n",
    "the difference between the target and the prediction is calculated and squared.\n",
    "this is added to the total cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(x, y, w, b): \n",
    "    \"\"\"\n",
    "    Computes the cost function for linear regression.\n",
    "    \n",
    "    Args:\n",
    "      x (ndarray (m,)): Data, m examples \n",
    "      y (ndarray (m,)): target values\n",
    "      w,b (scalar)    : model parameters  \n",
    "    \n",
    "    Returns\n",
    "        total_cost (float): The cost of using w,b as the parameters for linear regression\n",
    "               to fit the data points in x and y\n",
    "    \"\"\"\n",
    "    # number of training examples\n",
    "    m = x.shape[0] \n",
    "    \n",
    "    cost_sum = 0 \n",
    "    for i in range(m): \n",
    "        f_wb = w * x[i] + b   \n",
    "        cost = (f_wb - y[i]) ** 2  \n",
    "        cost_sum = cost_sum + cost  \n",
    "    total_cost = (1 / (2 * m)) * cost_sum  \n",
    "\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_intuition(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot contains a few points that are worth mentioning.\n",
    "cost is minimized when  ùë§=200\n",
    " , which matches results from the previous lab\n",
    "Because the difference between the target and pediction is squared in the cost equation, the cost increases rapidly when  ùë§ is either too large or too small. Using the w and b selected by minimizing cost results in a line which is a perfect fit to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost Function Visualization- 3D\n",
    "You can see how cost varies with respect to both w and b by plotting in 3D or using a contour plot.\n",
    "It is worth noting that some of the plotting in this course can become quite involved. The plotting routines are provided and while it can be instructive to read through the code to become familiar with the methods, it is not needed to complete the course successfully. The routines are in lab_utils_uni.py in the local directory.\n",
    "Larger Data Set\n",
    "It's use instructive to view a scenario with a few more data points. This data set includes data points that do not fall on the same line. What does that mean for the cost equation? Can we find ùë§\n",
    "w\n",
    ", and ùëè\n",
    "b\n",
    " that will give us a cost of 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([1.0, 1.7, 2.0, 2.5, 3.0, 3.2])\n",
    "y_train = np.array([250, 300, 480,  430,   630, 730,])\n",
    "\n",
    "#In the contour plot, click on a point to select w and b to achieve the lowest cost.\n",
    "# Use the contours to guide your selections. Note, it can take a few seconds to update the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all') \n",
    "fig, ax, dyn_items = plt_stationary(x_train, y_train)\n",
    "updater = plt_update_onclick(fig, ax, x_train, y_train, dyn_items)\n",
    "\n",
    "#Above, note the dashed lines in the left plot. These represent the portion of the cost contributed by each example in your training set.\n",
    "#  In this case, values of approximately  ùë§=209 and  ùëè=2.4 provide low cost. Note that, because our training examples are not on a line,\n",
    "#  the minimum cost is not zero.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convex Cost surface\n",
    "The fact that the cost function squares the loss ensures that the 'error surface' is convex like a soup bowl. It will always have a minimum that can be reached by following the gradient in all dimensions. In the previous plot, because the  ùë§  and  ùëè dimensions scale differently, this is not easy to recognize. The following plot, where  ùë§ and  ùëè are symmetric, was shown in lecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_bowl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have learned the following:\n",
    "The cost equation provides a measure of how well your predictions match your training data.\n",
    "Minimizing the cost can provide optimal values of  ùë§,ùëè"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goals\n",
    "In this lab, you will:\n",
    "automate the process of optimizing  ùë§ and  ùëè using gradient descent.\n",
    "\n",
    "Tools\n",
    "In this lab, we will make use of:\n",
    "NumPy, a popular library for scientific computing\n",
    "Matplotlib, a popular library for plotting data\n",
    "plotting routines in the lab_utils.py file in the local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('./deeplearning.mplstyle')\n",
    "from lab_utils_uni import plt_house_x, plt_contour_wgrad, plt_divergence, plt_gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Statement\n",
    "Let's use the same two data points as before - a house with 1000 square feet sold for $300,000 and a house with 2000 square feet sold for $500,000.\n",
    "Size (1000 sqft)\tPrice (1000s of dollars)\n",
    "1\t                         300\n",
    "2\t                         500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our data set\n",
    "x_train = np.array([1.0, 2.0])   #features\n",
    "y_train = np.array([300.0, 500.0])   #target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute_Cost\n",
    "#This was developed in the last lab. We'll need it again here.\n",
    "\n",
    "#Function to calculate the cost\n",
    "def compute_cost(x, y, w, b):\n",
    "   \n",
    "    m = x.shape[0] \n",
    "    cost = 0\n",
    "    \n",
    "    for i in range(m):\n",
    "        f_wb = w * x[i] + b\n",
    "        cost = cost + (f_wb - y[i])**2\n",
    "    total_cost = 1 / (2 * m) * cost\n",
    "\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(x, y, w, b): \n",
    "    \"\"\"\n",
    "    Computes the gradient for linear regression \n",
    "    Args:\n",
    "      x (ndarray (m,)): Data, m examples \n",
    "      y (ndarray (m,)): target values\n",
    "      w,b (scalar)    : model parameters  \n",
    "    Returns\n",
    "      dj_dw (scalar): The gradient of the cost w.r.t. the parameters w\n",
    "      dj_db (scalar): The gradient of the cost w.r.t. the parameter b     \n",
    "     \"\"\"\n",
    "    \n",
    "    # Number of training examples\n",
    "    m = x.shape[0]    \n",
    "    dj_dw = 0\n",
    "    dj_db = 0\n",
    "    \n",
    "    for i in range(m):  \n",
    "        f_wb = w * x[i] + b \n",
    "        dj_dw_i = (f_wb - y[i]) * x[i] \n",
    "        dj_db_i = f_wb - y[i] \n",
    "        dj_db += dj_db_i\n",
    "        dj_dw += dj_dw_i \n",
    "    dj_dw = dj_dw / m \n",
    "    dj_db = dj_db / m \n",
    "        \n",
    "    return dj_dw, dj_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_gradients(x_train,y_train, compute_cost, compute_gradient)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, w_in, b_in, alpha, num_iters, cost_function, gradient_function): \n",
    "    \"\"\"\n",
    "    Performs gradient descent to fit w,b. Updates w,b by taking \n",
    "    num_iters gradient steps with learning rate alpha\n",
    "    \n",
    "    Args:\n",
    "      x (ndarray (m,))  : Data, m examples \n",
    "      y (ndarray (m,))  : target values\n",
    "      w_in,b_in (scalar): initial values of model parameters  \n",
    "      alpha (float):     Learning rate\n",
    "      num_iters (int):   number of iterations to run gradient descent\n",
    "      cost_function:     function to call to produce cost\n",
    "      gradient_function: function to call to produce gradient\n",
    "      \n",
    "    Returns:\n",
    "      w (scalar): Updated value of parameter after running gradient descent\n",
    "      b (scalar): Updated value of parameter after running gradient descent\n",
    "      J_history (List): History of cost values\n",
    "      p_history (list): History of parameters [w,b] \n",
    "      \"\"\"\n",
    "    \n",
    "    w = copy.deepcopy(w_in) # avoid modifying global w_in\n",
    "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
    "    J_history = []\n",
    "    p_history = []\n",
    "    b = b_in\n",
    "    w = w_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        # Calculate the gradient and update the parameters using gradient_function\n",
    "        dj_dw, dj_db = gradient_function(x, y, w , b)     \n",
    "\n",
    "        # Update Parameters using equation (3) above\n",
    "        b = b - alpha * dj_db                            \n",
    "        w = w - alpha * dj_dw                            \n",
    "\n",
    "        # Save cost J at each iteration\n",
    "        if i<100000:      # prevent resource exhaustion \n",
    "            J_history.append( cost_function(x, y, w , b))\n",
    "            p_history.append([w,b])\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i% math.ceil(num_iters/10) == 0:\n",
    "            print(f\"Iteration {i:4}: Cost {J_history[-1]:0.2e} \",\n",
    "                  f\"dj_dw: {dj_dw: 0.3e}, dj_db: {dj_db: 0.3e}  \",\n",
    "                  f\"w: {w: 0.3e}, b:{b: 0.5e}\")\n",
    " \n",
    "    return w, b, J_history, p_history #return w and J,w history for graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters\n",
    "w_init = 0\n",
    "b_init = 0\n",
    "# some gradient descent settings\n",
    "iterations = 10000\n",
    "tmp_alpha = 1.0e-2\n",
    "# run gradient descent\n",
    "w_final, b_final, J_hist, p_hist = gradient_descent(x_train ,y_train, w_init, b_init, tmp_alpha, \n",
    "                                                    iterations, compute_cost, compute_gradient)\n",
    "print(f\"(w,b) found by gradient descent: ({w_final:8.4f},{b_final:8.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost versus iterations of gradient descent\n",
    "A plot of cost versus iterations is a useful measure of progress in gradient descent. Cost should always decrease in successful runs. The change in cost is so rapid initially, it is useful to plot the initial decent on a different scale than the final descent. In the plots below, note the scale of cost on the axes and the iteration step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot cost versus iteration  \n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, constrained_layout=True, figsize=(12,4))\n",
    "ax1.plot(J_hist[:100])\n",
    "ax2.plot(1000 + np.arange(len(J_hist[1000:])), J_hist[1000:])\n",
    "ax1.set_title(\"Cost vs. iteration(start)\");  ax2.set_title(\"Cost vs. iteration (end)\")\n",
    "ax1.set_ylabel('Cost')            ;  ax2.set_ylabel('Cost') \n",
    "ax1.set_xlabel('iteration step')  ;  ax2.set_xlabel('iteration step') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions\n",
    "Now that you have discovered the optimal values for the parameters  ùë§ and  ùëè, you can now use the model to predict housing values based on our learned parameters. As expected, the predicted values are nearly the same as the training values for the same housing. Further, the value not in the prediction is in line with the expected value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"1000 sqft house prediction {w_final*1.0 + b_final:0.1f} Thousand dollars\")\n",
    "print(f\"1200 sqft house prediction {w_final*1.2 + b_final:0.1f} Thousand dollars\")\n",
    "print(f\"2000 sqft house prediction {w_final*2.0 + b_final:0.1f} Thousand dollars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting\n",
    "#You can show the progress of gradient descent during its execution by plotting the cost over iterations on a contour plot of the cost(w,b).\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(12, 6))\n",
    "plt_contour_wgrad(x_train, y_train, p_hist, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, the contour plot shows the  ùëêùëúùë†ùë°(ùë§,ùëè)\n",
    "  over a range of  ùë§ and  ùëè. Cost levels are represented by the rings. Overlayed, using red arrows, is the path of gradient descent. \n",
    "Here are some things to note:\n",
    "The path makes steady (monotonic) progress toward its goal.\n",
    "initial steps are much larger than the steps near the goal.\n",
    "Zooming in, we can see that final steps of gradient descent. Note the distance between steps shrinks as the gradient approaches zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(12, 4))\n",
    "plt_contour_wgrad(x_train, y_train, p_hist, ax, w_range=[180, 220, 0.5], b_range=[80, 120, 0.5],\n",
    "            contours=[1,5,10,20],resolution=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters\n",
    "w_init = 0\n",
    "b_init = 0\n",
    "# set alpha to a large value\n",
    "iterations = 10\n",
    "tmp_alpha = 8.0e-1\n",
    "# run gradient descent\n",
    "w_final, b_final, J_hist, p_hist = gradient_descent(x_train ,y_train, w_init, b_init, tmp_alpha, \n",
    "                                                    iterations, compute_cost, compute_gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above,  ùë§ and  ùëè are bouncing back and forth between positive and negative with the absolute value increasing with each iteration. Further, each iteration  ‚àÇùêΩ(ùë§,ùëè)/‚àÇùë§\n",
    "changes sign and cost is increasing rather than decreasing. This is a clear sign that the learning rate is too large and the solution is diverging. Let's visualize this with a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_divergence(p_hist, J_hist,x_train, y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, the left graph shows  ùë§'s progression over the first few steps of gradient descent.  ùë§ oscillates from positive to negative and cost grows rapidly. Gradient Descent is operating on both  ùë§ and  ùëèsimultaneously, so one needs the 3-D plot on the right for the complete picture.\n",
    "\n",
    "In this lab you:\n",
    "delved into the details of gradient descent for a single variable.\n",
    "developed a routine to compute the gradient\n",
    "visualized what the gradient is\n",
    "completed a gradient descent routine\n",
    "utilized gradient descent to find parameters\n",
    "examined the impact of sizing the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nearest-square\n",
      "  Downloading nearest_square-1.5.tar.gz (942 bytes)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: nearest-square\n",
      "  Building wheel for nearest-square (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nearest-square: filename=nearest_square-1.5-py3-none-any.whl size=1641 sha256=5f601ce06e17e852a9cfce58d18d240748b912bc391e450c5e314917b59cfe89\n",
      "  Stored in directory: /Users/likhithrajnanneboyina/Library/Caches/pip/wheels/da/fd/1e/96aa1cef9bd55d62e4b7adf60cc076aba540687b10854ddbe2\n",
      "Successfully built nearest-square\n",
      "Installing collected packages: nearest-square\n",
      "Successfully installed nearest-square-1.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nearest-square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected result: 36,actual result:36\n"
     ]
    }
   ],
   "source": [
    "def nearest_square(limit):\n",
    "    limit = limit ** (0.5)\n",
    "    y = int (limit)\n",
    "    while y < limit :\n",
    "         y = y*y\n",
    "    return y\n",
    "\n",
    "test1 = nearest_square(40)\n",
    "print(\"expected result: 36,actual result:{}\".format(test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_validator(email):\n",
    " if email.count('@')!= 0 and email.count('.')!= 0:\n",
    "  return True\n",
    " else:\n",
    "  return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_validator(email):\n",
    " if email.count('@') == 1 and email.count('.') == 1:\n",
    "  return True\n",
    " else:\n",
    "  return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raj\n"
     ]
    }
   ],
   "source": [
    "def email_validator(email):\n",
    " if email.count('@')!=0\\\n",
    "and email.count('.')!=0:\n",
    "  return True\n",
    " else:\n",
    "  return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rzj\n"
     ]
    }
   ],
   "source": [
    "def test_email_validator():\n",
    " assert email_validator('juno@email.com') == True\n",
    " assert email_validator('juno@email@.com') == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1]\n",
    "clf = svm.SVC()\n",
    "clf.fit(X, y)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional Lab: Python, NumPy and Vectorization\n",
    "\n",
    "A brief introduction to some of the scientific computing used in this course. In particular the NumPy scientific computing package and its use with python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np    # it is an unofficial standard to use np for numpy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.zeros(4) :   a = [0. 0. 0. 0.], a shape = (4,), a data type = float64\n",
      "np.zeros(4,) :  a = [0. 0. 0. 0.], a shape = (4,), a data type = float64\n",
      "np.random.random_sample(4): a = [0.23971142 0.54325914 0.62811845 0.76489784], a shape = (4,), a data type = float64\n"
     ]
    }
   ],
   "source": [
    "# Data creation routines in NumPy will generally have a first parameter which is the shape of the object. \n",
    "# This can either be a single value for a 1-D result or a tuple (n,m,...) specifying the shape of the result. \n",
    "# Below are examples of creating vectors using these routines.\n",
    "\n",
    "# NumPy routines which allocate memory and fill arrays with value\n",
    "a = np.zeros(4);                print(f\"np.zeros(4) :   a = {a}, a shape = {a.shape}, a data type = {a.dtype}\")\n",
    "a = np.zeros((4,));             print(f\"np.zeros(4,) :  a = {a}, a shape = {a.shape}, a data type = {a.dtype}\")\n",
    "a = np.random.random_sample(4); print(f\"np.random.random_sample(4): a = {a}, a shape = {a.shape}, a data type = {a.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.arange(4.):     a = [0. 1. 2. 3.], a shape = (4,), a data type = float64\n",
      "np.random.rand(4): a = [0.53026345 0.07333975 0.8248665  0.06351551], a shape = (4,), a data type = float64\n"
     ]
    }
   ],
   "source": [
    "# Some data creation routines do not take a shape tuple:\n",
    "# NumPy routines which allocate memory and fill arrays with value but do not accept shape as input argument\n",
    "\n",
    "a = np.arange(4.);              print(f\"np.arange(4.):     a = {a}, a shape = {a.shape}, a data type = {a.dtype}\")\n",
    "a = np.random.rand(4);          print(f\"np.random.rand(4): a = {a}, a shape = {a.shape}, a data type = {a.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.array([5,4,3,2]):  a = [5 4 3 2],     a shape = (4,), a data type = int64\n",
      "np.array([5.,4,3,2]): a = [5. 4. 3. 2.], a shape = (4,), a data type = float64\n"
     ]
    }
   ],
   "source": [
    "# values can be specified manually as well.\n",
    "\n",
    "# NumPy routines which allocate memory and fill with user specified values\n",
    "a = np.array([5,4,3,2]);  print(f\"np.array([5,4,3,2]):  a = {a},     a shape = {a.shape}, a data type = {a.dtype}\")\n",
    "a = np.array([5.,4,3,2]); print(f\"np.array([5.,4,3,2]): a = {a}, a shape = {a.shape}, a data type = {a.dtype}\")\n",
    "\n",
    "# These have all created a one-dimensional vector  a with four elements. a.shape returns the dimensions.\n",
    "#  Here we see a.shape = (4,) indicating a 1-d array with 4 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "a[2].shape: () a[2]  = 2, Accessing an element returns a scalar\n",
      "a[-1] = 9\n",
      "The error message you'll see is:\n",
      "index 10 is out of bounds for axis 0 with size 10\n"
     ]
    }
   ],
   "source": [
    "#Operations on Vectors\n",
    "#vector indexing operations on 1-D vectors\n",
    "a = np.arange(10)\n",
    "print(a)\n",
    "\n",
    "#access an element\n",
    "print(f\"a[2].shape: {a[2].shape} a[2]  = {a[2]}, Accessing an element returns a scalar\")\n",
    "\n",
    "# access the last element, negative indexes count from the end\n",
    "print(f\"a[-1] = {a[-1]}\")\n",
    "\n",
    "#indexs must be within the range of the vector or they will produce and error\n",
    "try:\n",
    "    c = a[10]\n",
    "except Exception as e:\n",
    "    print(\"The error message you'll see is:\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a         = [0 1 2 3 4 5 6 7 8 9]\n",
      "a[2:7:1] =  [2 3 4 5 6]\n",
      "a[2:7:2] =  [2 4 6]\n",
      "a[3:]    =  [3 4 5 6 7 8 9]\n",
      "a[:3]    =  [0 1 2]\n",
      "a[:]     =  [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Slicing\n",
    "#  Slicing creates an array of indices using a set of three values (start:stop:step).\n",
    "#  A subset of values is also valid. Its use is best explained by example:\n",
    "\n",
    "#vector slicing operations\n",
    "a = np.arange(10)\n",
    "print(f\"a         = {a}\")\n",
    "\n",
    "#access 5 consecutive elements (start:stop:step)\n",
    "c = a[2:7:1];     print(\"a[2:7:1] = \", c)\n",
    "\n",
    "# access 3 elements separated by two \n",
    "c = a[2:7:2];     print(\"a[2:7:2] = \", c)\n",
    "\n",
    "# access all elements index 3 and above\n",
    "c = a[3:];        print(\"a[3:]    = \", c)\n",
    "\n",
    "# access all elements below index 3\n",
    "c = a[:3];        print(\"a[:3]    = \", c)\n",
    "\n",
    "# access all elements\n",
    "c = a[:];         print(\"a[:]     = \", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a             : [1 2 3 4]\n",
      "b = -a        : [-1 -2 -3 -4]\n",
      "b = np.sum(a) : 10\n",
      "b = np.mean(a): 2.5\n",
      "b = a**2      : [ 1  4  9 16]\n"
     ]
    }
   ],
   "source": [
    "#Single vector operations\n",
    "# There are a number of useful operations that involve operations on a single vector.\n",
    "a = np.array([1,2,3,4])\n",
    "print(f\"a             : {a}\")\n",
    "# negate elements of a\n",
    "b = -a \n",
    "print(f\"b = -a        : {b}\")\n",
    "\n",
    "# sum all elements of a, returns a scalar\n",
    "b = np.sum(a) \n",
    "print(f\"b = np.sum(a) : {b}\")\n",
    "\n",
    "b = np.mean(a)\n",
    "print(f\"b = np.mean(a): {b}\")\n",
    "\n",
    "b = a**2\n",
    "print(f\"b = a**2      : {b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary operators work element wise: [0 0 6 8]\n"
     ]
    }
   ],
   "source": [
    "#Vector Vector element-wise operations\n",
    "#Most of the NumPy arithmetic, logical and comparison operations apply to vectors as well.\n",
    "#  These operators work on an element-by-element basis. For example\n",
    "#                         ùëêùëñ=ùëéùëñ+ùëèùëñ\n",
    "\n",
    "a = np.array([ 1, 2, 3, 4])\n",
    "b = np.array([-1,-2, 3, 4])\n",
    "print(f\"Binary operators work element wise: {a + b}\")\n",
    "\n",
    "#Of course, for this to work correctly, the vectors must be of the same size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error message you'll see is:\n",
      "operands could not be broadcast together with shapes (4,) (2,) \n"
     ]
    }
   ],
   "source": [
    "#try a mismatched vector operation\n",
    "c = np.array([1, 2])\n",
    "try:\n",
    "    d = a + c\n",
    "except Exception as e:\n",
    "    print(\"The error message you'll see is:\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b = 5 * a : [ 5 10 15 20]\n"
     ]
    }
   ],
   "source": [
    "#Scalar Vector operations\n",
    "# Vectors can be 'scaled' by scalar values. A scalar value is just a number. The scalar multiplies all the elements of the vector.\n",
    "\n",
    "a = np.array([1, 2, 3, 4])\n",
    "\n",
    "# multiply a by a scalar\n",
    "b = 5 * a \n",
    "print(f\"b = 5 * a : {b}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vector Vector dot product\n",
    "# The dot product is a mainstay of Linear Algebra and NumPy. \n",
    "# This is an operation used extensively in this course and should be well understood. The dot product is shown below.\n",
    "#  Assume both a and b are the same shape.\n",
    "\n",
    "\n",
    "def my_dot(a, b): \n",
    "    \"\"\"\n",
    "   Compute the dot product of two vectors\n",
    " \n",
    "    Args:\n",
    "      a (ndarray (n,)):  input vector \n",
    "      b (ndarray (n,)):  input vector with same dimension as a\n",
    "    \n",
    "    Returns:\n",
    "      x (scalar): \n",
    "    \"\"\"\n",
    "    x=0\n",
    "    for i in range(a.shape[0]):\n",
    "        x = x + a[i] * b[i]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_dot(a, b) = 24\n"
     ]
    }
   ],
   "source": [
    "# test 1-D\n",
    "a = np.array([1, 2, 3, 4])\n",
    "b = np.array([-1, 4, 3, 2])\n",
    "print(f\"my_dot(a, b) = {my_dot(a, b)}\")\n",
    "\n",
    "# Note, the dot product is expected to return a scalar value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try the same operations using np.dot\n",
    "\n",
    "# test 1-D\n",
    "a = np.array([1, 2, 3, 4])\n",
    "b = np.array([-1, 4, 3, 2])\n",
    "c = np.dot(a, b)\n",
    "print(f\"NumPy 1-D np.dot(a, b) = {c}, np.dot(a, b).shape = {c.shape} \") \n",
    "c = np.dot(b, a)\n",
    "print(f\"NumPy 1-D np.dot(b, a) = {c}, np.dot(a, b).shape = {c.shape} \")\n",
    "\n",
    "# Above, you will note that the results for 1-D matched our implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Need for Speed: vector vs for loop\n",
    "# We utilized the NumPy library because it improves speed memory efficiency. Let's demonstrate:\n",
    "\n",
    "np.random.seed(1)\n",
    "a = np.random.rand(10000000)  # very large arrays\n",
    "b = np.random.rand(10000000)\n",
    "\n",
    "tic = time.time()  # capture start time\n",
    "c = np.dot(a, b)\n",
    "toc = time.time()  # capture end time\n",
    "\n",
    "print(f\"np.dot(a, b) =  {c:.4f}\")\n",
    "print(f\"Vectorized version duration: {1000*(toc-tic):.4f} ms \")\n",
    "\n",
    "tic = time.time()  # capture start time\n",
    "c = my_dot(a,b)\n",
    "toc = time.time()  # capture end time\n",
    "\n",
    "print(f\"my_dot(a, b) =  {c:.4f}\")\n",
    "print(f\"loop version duration: {1000*(toc-tic):.4f} ms \")\n",
    "\n",
    "del(a);del(b)  #remove these big arrays from memory\n",
    "\n",
    "# So, vectorization provides a large speed up in this example. \n",
    "# This is because NumPy makes better use of available data parallelism in the underlying hardware.\n",
    "# GPU's and modern CPU's implement Single Instruction, Multiple Data (SIMD) pipelines allowing multiple operations to be issued in parallel.\n",
    "# This is critical in Machine Learning where the data sets are often very large.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector Vector operations in Course 1 \n",
    "\n",
    "Vector Vector operations will appear frequently in course 1. Here is why:\n",
    "\n",
    "- Going forward, our examples will be stored in an array, X_train of dimension (m,n). This will be explained more in context, but here it is important to note it is a 2 Dimensional array or matrix (see next section on matrices).\n",
    "\n",
    "- w will be a 1-dimensional vector of shape (n,).\n",
    "\n",
    "- we will perform operations by looping through the examples, extracting each example to work on individually by indexing X. For example:X[i]\n",
    "\n",
    "- X[i] returns a value of shape (n,), a 1-dimensional vector. Consequently, operations involving X[i] are often vector-vector.\n",
    "\n",
    "That is a somewhat lengthy explanation, but aligning and understanding the shapes of your operands is important when performing vector operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X[1] has shape (1,)\n",
      "w has shape (1,)\n",
      "c has shape ()\n"
     ]
    }
   ],
   "source": [
    "# show common Course 1 example\n",
    "X = np.array([[1],[2],[3],[4]])\n",
    "w = np.array([2])\n",
    "c = np.dot(X[1], w)\n",
    "\n",
    "print(f\"X[1] has shape {X[1].shape}\")\n",
    "print(f\"w has shape {w.shape}\")\n",
    "print(f\"c has shape {c.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a shape = (1, 5), a = [[0. 0. 0. 0. 0.]]\n",
      "a shape = (2, 1), a = [[0.]\n",
      " [0.]]\n",
      "a shape = (1, 1), a = [[0.41166754]]\n"
     ]
    }
   ],
   "source": [
    "# Matrices\n",
    "\n",
    "# Matrix Creation \n",
    "\n",
    "# The same functions that created 1-D vectors will create 2-D or n-D arrays. Here are some examples \n",
    "# Below, the shape tuple is provided to achieve a 2-D result. Notice how NumPy uses brackets to denote each dimension. \n",
    "# Notice further than NumPy, when printing, will print one row per line.\n",
    "\n",
    "a = np.zeros((1, 5))                                       \n",
    "print(f\"a shape = {a.shape}, a = {a}\")                     \n",
    "\n",
    "a = np.zeros((2, 1))                                                                   \n",
    "print(f\"a shape = {a.shape}, a = {a}\") \n",
    "\n",
    "a = np.random.random_sample((1, 1))  \n",
    "print(f\"a shape = {a.shape}, a = {a}\") \n",
    "\n",
    "# One can also manually specify data. Dimensions are specified with additional brackets matching the format in the printing above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a shape = (3, 1), np.array: a = [[5]\n",
      " [4]\n",
      " [3]]\n",
      " a shape = (3, 1), np.array: a = [[5]\n",
      " [4]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "# NumPy routines which allocate memory and fill with user specified values\n",
    "a = np.array([[5], [4], [3]]);   print(f\" a shape = {a.shape}, np.array: a = {a}\")\n",
    "a = np.array([[5],   # One can also\n",
    "              [4],   # separate values\n",
    "              [3]]); #into separate rows\n",
    "print(f\" a shape = {a.shape}, np.array: a = {a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.shape: (3, 2), \n",
      "a= [[0 1]\n",
      " [2 3]\n",
      " [4 5]]\n",
      "\n",
      "a[2,0].shape:   (), a[2,0] = 4,     type(a[2,0]) = <class 'numpy.int64'> Accessing an element returns a scalar\n",
      "\n",
      "a[2].shape:   (2,), a[2]   = [4 5], type(a[2])   = <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Operations on Matrices \n",
    "# Let's explore some operations using matrices.\n",
    "\n",
    "# Indexin \n",
    "# Matrices include a second index. The two indexes describe [row, column]. Access can either return an element or a row/column. See below:\n",
    "\n",
    "\n",
    "#vector indexing operations on matrices\n",
    "a = np.arange(6).reshape(-1, 2)   #reshape is a convenient way to create matrices\n",
    "print(f\"a.shape: {a.shape}, \\na= {a}\")\n",
    "\n",
    "#access an element\n",
    "print(f\"\\na[2,0].shape:   {a[2, 0].shape}, a[2,0] = {a[2, 0]},     type(a[2,0]) = {type(a[2, 0])} Accessing an element returns a scalar\\n\")\n",
    "\n",
    "#access a row\n",
    "print(f\"a[2].shape:   {a[2].shape}, a[2]   = {a[2]}, type(a[2])   = {type(a[2])}\")\n",
    "\n",
    "# It is worth drawing attention to the last example. Accessing a matrix by just specifying the row will return a 1-D vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape\n",
    "\n",
    "The previous example used reshape to shape the array.\n",
    "a = np.arange(6).reshape(-1, 2)\n",
    "This line of code first created a 1-D Vector of six elements. It then reshaped that vector into a 2-D array using the reshape command. This could have been \n",
    "\n",
    "written:\n",
    "a = np.arange(6).reshape(3, 2)\n",
    "To arrive at the same 3 row, 2 column array. The -1 argument tells the routine to compute the number of rows given the size of the array and the number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = \n",
      "[[ 0  1  2  3  4  5  6  7  8  9]\n",
      " [10 11 12 13 14 15 16 17 18 19]]\n",
      "a[0, 2:7:1] =  [2 3 4 5 6] ,  a[0, 2:7:1].shape = (5,) a 1-D array\n",
      "a[:, 2:7:1] = \n",
      " [[ 2  3  4  5  6]\n",
      " [12 13 14 15 16]] ,  a[:, 2:7:1].shape = (2, 5) a 2-D array\n",
      "a[:,:] = \n",
      " [[ 0  1  2  3  4  5  6  7  8  9]\n",
      " [10 11 12 13 14 15 16 17 18 19]] ,  a[:,:].shape = (2, 10)\n",
      "a[1,:] =  [10 11 12 13 14 15 16 17 18 19] ,  a[1,:].shape = (10,) a 1-D array\n",
      "a[1]   =  [10 11 12 13 14 15 16 17 18 19] ,  a[1].shape   = (10,) a 1-D array\n"
     ]
    }
   ],
   "source": [
    "# Slicing\n",
    "# Slicing creates an array of indices using a set of three values (start:stop:step). \n",
    "# A subset of values is also valid. Its use is best explained by example:\n",
    "\n",
    "#vector 2-D slicing operations\n",
    "a = np.arange(20).reshape(-1, 10)\n",
    "print(f\"a = \\n{a}\")\n",
    "\n",
    "#access 5 consecutive elements (start:stop:step)\n",
    "print(\"a[0, 2:7:1] = \", a[0, 2:7:1], \",  a[0, 2:7:1].shape =\", a[0, 2:7:1].shape, \"a 1-D array\")\n",
    "\n",
    "#access 5 consecutive elements (start:stop:step) in two rows\n",
    "print(\"a[:, 2:7:1] = \\n\", a[:, 2:7:1], \",  a[:, 2:7:1].shape =\", a[:, 2:7:1].shape, \"a 2-D array\")\n",
    "\n",
    "# access all elements\n",
    "print(\"a[:,:] = \\n\", a[:,:], \",  a[:,:].shape =\", a[:,:].shape)\n",
    "\n",
    "# access all elements in one row (very common usage)\n",
    "print(\"a[1,:] = \", a[1,:], \",  a[1,:].shape =\", a[1,:].shape, \"a 1-D array\")\n",
    "# same as\n",
    "print(\"a[1]   = \", a[1],   \",  a[1].shape   =\", a[1].shape, \"a 1-D array\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Multiple Variable Linear Regression\n",
    " \n",
    "In this lab, you will extend the data structures and previously developed routines to support multiple features.\n",
    " Several routines are updated making the lab appear lengthy, but it makes minor adjustments to previous routines making it quick to review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('./deeplearning.mplstyle')\n",
    "np.set_printoptions(precision=2)  # reduced display precision on numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem Statement\n",
    "\n",
    "X_train = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
    "y_train = np.array([460, 232, 178])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape: (3, 4), X Type:<class 'numpy.ndarray'>)\n",
      "[[2104    5    1   45]\n",
      " [1416    3    2   40]\n",
      " [ 852    2    1   35]]\n",
      "y Shape: (3,), y Type:<class 'numpy.ndarray'>)\n",
      "[460 232 178]\n"
     ]
    }
   ],
   "source": [
    "# data is stored in numpy array/matrix\n",
    "print(f\"X Shape: {X_train.shape}, X Type:{type(X_train)})\")\n",
    "print(X_train)\n",
    "print(f\"y Shape: {y_train.shape}, y Type:{type(y_train)})\")\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_init shape: (4,), b_init type: <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# Parameter vector w, b\n",
    "b_init = 785.1811367994083\n",
    "w_init = np.array([ 0.39133535, 18.75376741, -53.36032453, -26.42131618])\n",
    "print(f\"w_init shape: {w_init.shape}, b_init type: {type(b_init)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Prediction element by element\n",
    "# Our previous prediction multiplied one feature value by one parameter and added a bias parameter. \n",
    "# A direct extension of our previous implementation of prediction to multiple features would be to implement (1) \n",
    "# above using loop over each element, performing the multiply with its parameter and then adding the bias parameter at the end.\n",
    "\n",
    "\n",
    "def predict_single_loop(x, w, b): \n",
    "    \"\"\"\n",
    "    single predict using linear regression\n",
    "    \n",
    "    Args:\n",
    "      x (ndarray): Shape (n,) example with multiple features\n",
    "      w (ndarray): Shape (n,) model parameters    \n",
    "      b (scalar):  model parameter     \n",
    "      \n",
    "    Returns:\n",
    "      p (scalar):  prediction\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "    p = 0\n",
    "    for i in range(n):\n",
    "        p_i = x[i] * w[i]  \n",
    "        p = p + p_i         \n",
    "    p = p + b                \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_vec shape (4,), x_vec value: [2104    5    1   45]\n",
      "f_wb shape (), prediction: 459.9999976194083\n"
     ]
    }
   ],
   "source": [
    "# get a row from our training data\n",
    "x_vec = X_train[0,:]\n",
    "print(f\"x_vec shape {x_vec.shape}, x_vec value: {x_vec}\")\n",
    "\n",
    "# make a prediction\n",
    "f_wb = predict_single_loop(x_vec, w_init, b_init)\n",
    "print(f\"f_wb shape {f_wb.shape}, prediction: {f_wb}\")\n",
    "\n",
    "# Note the shape of x_vec. It is a 1-D NumPy vector with 4 elements, (4,). The result, f_wb is a scalar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Single Prediction, vector\n",
    " \n",
    "Noting that equation (1) above can be implemented using the dot product as in (2) above. We can make use of vector operations to speed up predictions.\n",
    "Recall from the Python/Numpy lab that NumPy np.dot()[link] can be used to perform a vector dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, w, b): \n",
    "    \"\"\"\n",
    "    single predict using linear regression\n",
    "    Args:\n",
    "      x (ndarray): Shape (n,) example with multiple features\n",
    "      w (ndarray): Shape (n,) model parameters   \n",
    "      b (scalar):             model parameter \n",
    "      \n",
    "    Returns:\n",
    "      p (scalar):  prediction\n",
    "    \"\"\"\n",
    "    p = np.dot(x, w) + b     \n",
    "    return p    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_vec shape (4,), x_vec value: [2104    5    1   45]\n",
      "f_wb shape (), prediction: 459.9999976194083\n"
     ]
    }
   ],
   "source": [
    "# get a row from our training data\n",
    "x_vec = X_train[0,:]\n",
    "print(f\"x_vec shape {x_vec.shape}, x_vec value: {x_vec}\")\n",
    "\n",
    "# make a prediction\n",
    "f_wb = predict(x_vec,w_init, b_init)\n",
    "print(f\"f_wb shape {f_wb.shape}, prediction: {f_wb}\")\n",
    "\n",
    "# The results and shapes are the same as the previous version which used looping. Going forward, np.dot will be used for these operations. The prediction is now a single statement. Most routines will implement it directly rather than calling a separate predict routine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Cost With Multiple Variables\n",
    "\n",
    "\n",
    "def compute_cost(X, y, w, b): \n",
    "    \"\"\"\n",
    "    compute cost\n",
    "    Args:\n",
    "      X (ndarray (m,n)): Data, m examples with n features\n",
    "      y (ndarray (m,)) : target values\n",
    "      w (ndarray (n,)) : model parameters  \n",
    "      b (scalar)       : model parameter\n",
    "      \n",
    "    Returns:\n",
    "      cost (scalar): cost\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    cost = 0.0\n",
    "    for i in range(m):                                \n",
    "        f_wb_i = np.dot(X[i], w) + b           #(n,)(n,) = scalar (see np.dot)\n",
    "        cost = cost + (f_wb_i - y[i])**2       #scalar\n",
    "    cost = cost / (2 * m)                      #scalar    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at optimal w : 1.5578904045996674e-12\n"
     ]
    }
   ],
   "source": [
    "# Compute and display cost using our pre-chosen optimal parameters. \n",
    "cost = compute_cost(X_train, y_train, w_init, b_init)\n",
    "print(f'Cost at optimal w : {cost}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Gradient with Multiple Variables\n",
    "\n",
    "def compute_gradient(X, y, w, b): \n",
    "    \"\"\"\n",
    "    Computes the gradient for linear regression \n",
    "    Args:\n",
    "      X (ndarray (m,n)): Data, m examples with n features\n",
    "      y (ndarray (m,)) : target values\n",
    "      w (ndarray (n,)) : model parameters  \n",
    "      b (scalar)       : model parameter\n",
    "      \n",
    "    Returns:\n",
    "      dj_dw (ndarray (n,)): The gradient of the cost w.r.t. the parameters w. \n",
    "      dj_db (scalar):       The gradient of the cost w.r.t. the parameter b. \n",
    "    \"\"\"\n",
    "    m,n = X.shape           #(number of examples, number of features)\n",
    "    dj_dw = np.zeros((n,))\n",
    "    dj_db = 0.\n",
    "\n",
    "    for i in range(m):                             \n",
    "        err = (np.dot(X[i], w) + b) - y[i]   \n",
    "        for j in range(n):                         \n",
    "            dj_dw[j] = dj_dw[j] + err * X[i, j]    \n",
    "        dj_db = dj_db + err                        \n",
    "    dj_dw = dj_dw / m                                \n",
    "    dj_db = dj_db / m                                \n",
    "        \n",
    "    return dj_db, dj_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db at initial w,b: -1.6739251122999121e-06\n",
      "dj_dw at initial w,b: \n",
      " [-2.72623574e-03 -6.27197255e-06 -2.21745574e-06 -6.92403377e-05]\n"
     ]
    }
   ],
   "source": [
    "#Compute and display gradient \n",
    "tmp_dj_db, tmp_dj_dw = compute_gradient(X_train, y_train, w_init, b_init)\n",
    "print(f'dj_db at initial w,b: {tmp_dj_db}')\n",
    "print(f'dj_dw at initial w,b: \\n {tmp_dj_dw}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent With Multiple Variables\n",
    "\n",
    "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters): \n",
    "    \"\"\"\n",
    "    Performs batch gradient descent to learn theta. Updates theta by taking \n",
    "    num_iters gradient steps with learning rate alpha\n",
    "    \n",
    "    Args:\n",
    "      X (ndarray (m,n))   : Data, m examples with n features\n",
    "      y (ndarray (m,))    : target values\n",
    "      w_in (ndarray (n,)) : initial model parameters  \n",
    "      b_in (scalar)       : initial model parameter\n",
    "      cost_function       : function to compute cost\n",
    "      gradient_function   : function to compute the gradient\n",
    "      alpha (float)       : Learning rate\n",
    "      num_iters (int)     : number of iterations to run gradient descent\n",
    "      \n",
    "    Returns:\n",
    "      w (ndarray (n,)) : Updated values of parameters \n",
    "      b (scalar)       : Updated value of parameter \n",
    "      \"\"\"\n",
    "    \n",
    "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
    "    J_history = []\n",
    "    w = copy.deepcopy(w_in)  #avoid modifying global w within function\n",
    "    b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Calculate the gradient and update the parameters\n",
    "        dj_db,dj_dw = gradient_function(X, y, w, b)   ##None\n",
    "\n",
    "        # Update Parameters using w, b, alpha and gradient\n",
    "        w = w - alpha * dj_dw               ##None\n",
    "        b = b - alpha * dj_db               ##None\n",
    "      \n",
    "        # Save cost J at each iteration\n",
    "        if i<100000:      # prevent resource exhaustion \n",
    "            J_history.append( cost_function(X, y, w, b))\n",
    "\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i% math.ceil(num_iters / 10) == 0:\n",
    "            print(f\"Iteration {i:4d}: Cost {J_history[-1]:8.2f}   \")\n",
    "        \n",
    "    return w, b, J_history #return final w,b and J history for graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost  2529.46   \n",
      "Iteration  100: Cost   695.99   \n",
      "Iteration  200: Cost   694.92   \n",
      "Iteration  300: Cost   693.86   \n",
      "Iteration  400: Cost   692.81   \n",
      "Iteration  500: Cost   691.77   \n",
      "Iteration  600: Cost   690.73   \n",
      "Iteration  700: Cost   689.71   \n",
      "Iteration  800: Cost   688.70   \n",
      "Iteration  900: Cost   687.69   \n",
      "b,w found by gradient descent: -0.00,[ 0.20396569  0.00374919 -0.0112487  -0.0658614 ] \n",
      "prediction: 426.19, target value: 460\n",
      "prediction: 286.17, target value: 232\n",
      "prediction: 171.47, target value: 178\n"
     ]
    }
   ],
   "source": [
    "# initialize parameters\n",
    "initial_w = np.zeros_like(w_init)\n",
    "initial_b = 0.\n",
    "# some gradient descent settings\n",
    "iterations = 1000\n",
    "alpha = 5.0e-7\n",
    "# run gradient descent \n",
    "w_final, b_final, J_hist = gradient_descent(X_train, y_train, initial_w, initial_b,\n",
    "                                                    compute_cost, compute_gradient, \n",
    "                                                    alpha, iterations)\n",
    "print(f\"b,w found by gradient descent: {b_final:0.2f},{w_final} \")\n",
    "m,_ = X_train.shape\n",
    "for i in range(m):\n",
    "    print(f\"prediction: {np.dot(X_train[i], w_final) + b_final:0.2f}, target value: {y_train[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot cost versus iteration  \n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, constrained_layout=True, figsize=(12, 4))\n",
    "ax1.plot(J_hist)\n",
    "ax2.plot(100 + np.arange(len(J_hist[100:])), J_hist[100:])\n",
    "ax1.set_title(\"Cost vs. iteration\");  ax2.set_title(\"Cost vs. iteration (tail)\")\n",
    "ax1.set_ylabel('Cost')             ;  ax2.set_ylabel('Cost') \n",
    "ax1.set_xlabel('iteration step')   ;  ax2.set_xlabel('iteration step') \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
